{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- PELICAN_BEGIN_SUMMARY -->\n",
    "\n",
    "This year I participated in Kaggle's March Madness Competition. However, this isn't your typical office pool; instead participants are tasked with assigning every possible match-up in the field of 64 with a probability that a certain team will win.\n",
    "\n",
    "In this post, I will describe my simple approach to building a machine learning model to predict winning percentages for March Madness games. Then, we'll see how it performed for this years competition!\n",
    "\n",
    "\n",
    "<!-- PELICAN_END_SUMMARY -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The best part of the March Madness kaggle competition is the data. Kaggle proves formatted regular season stats, play-by-play data, Tourney match-ups and results plus more running back to 2003, and some data back to 1985. \n",
    "\n",
    "The goal of the competition is to predict tournament match-ups with the lowest negative log loss score. Unlike normal bracket challenges, Kaggle doesn't ask you to predict just the winner of each game. Instead they want the probability that a team will win. Furthermore, we have to predict win probabilities for every possible game, which for a 64-slot bracket, with 4 play-in games, comes to a grand total of 2200 games. \n",
    "\n",
    "Submissions then comprise a 2200x2 vector where each row represents 1 of the possible matchups where the first column includes a string that defines a matchup such as 2014_UNC_vs_Clemson, and the second column represents the probability that the first team (UNC in this case) wins. Then the measure of success is judged as the log loss. This is defined as \n",
    "-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp)). When true, yt is 1, and yp is probability that yt is true. Here we're measuring the probability that yt is true on the conidition yp. Thus a perfect log loss score is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
